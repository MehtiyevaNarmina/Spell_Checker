{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic, good for understanding, but slow for long strings due to exponential time complexity (not the best option)\n",
    "# Time Complexity: O(3**n) (Exponential time complexity)\n",
    "\n",
    "def levenshtein_recursive(a, b):\n",
    "    if len(a) == 0:\n",
    "        return len(b)\n",
    "    if len(b) == 0:\n",
    "        return len(a)\n",
    "    \n",
    "    if a[-1] == b[-1]:\n",
    "        cost = 0\n",
    "    else:\n",
    "        cost = 1\n",
    "    \n",
    "    return min(levenshtein_recursive(a[:-1], b) + 1,\n",
    "               levenshtein_recursive(a, b[:-1]) + 1,\n",
    "               levenshtein_recursive(a[:-1], b[:-1]) + cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein_recursive('sunday', 'sand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Programming Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time complexitty: O(len1 × len2) in this case => O(6 × 4) = O(24) len(a) = 6 and len(b) = 4\n",
    "\n",
    "def levenshtein_distance_dp(a, b):\n",
    "    m, n = len(a), len(b)\n",
    "    distance_matrix = [[0] * (n + 1) for k in range(m + 1)]    \n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0:\n",
    "                distance_matrix[i][j] = j\n",
    "            elif j == 0:\n",
    "                distance_matrix[i][j] = i\n",
    "            else:\n",
    "                if a[i-1] == b[j-1]:\n",
    "                    cost = 0\n",
    "                else:\n",
    "                    cost = 1\n",
    "                distance_matrix[i][j] = min(distance_matrix[i-1][j] + 1,   \n",
    "                                distance_matrix[i][j-1] + 1,      \n",
    "                                distance_matrix[i-1][j-1] + cost) \n",
    "    \n",
    "    return distance_matrix[m][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein_distance_dp('sunday', 'sand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized Space Complexity (Using 1D Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time complexitty: O(len1 × len2) in this case => O(6 × 4) = O(24) len(a) = 6 and len(b) = 4\n",
    " \n",
    "def levenshtein_optimized_sc(a, b):\n",
    "    m, n = len(a), len(b)\n",
    "    prev = [j for j in range(n + 1)]\n",
    "    \n",
    "    for i in range(1, m + 1):\n",
    "        curr = [i] + [0] * n\n",
    "        for j in range(1, n + 1):\n",
    "            if a[i-1] == b[j-1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            curr[j] = min(prev[j] + 1,      # Deletion\n",
    "                           curr[j-1] + 1,    # Insertion\n",
    "                           prev[j-1] + cost) # Substitution\n",
    "        prev = curr\n",
    "    \n",
    "    return prev[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein_optimized_sc('sunday', 'sand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using Levenshtein Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "print(Levenshtein.distance('sunday', 'sand'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Damerau-Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time complexitty: O(len1 × len2) in this case => O(6 × 4) = O(24) len(a) = 6 and len(b) = 4\n",
    "\n",
    "def damerau_levenshtein_distance(a, b):\n",
    "    len1, len2 = len(a), len(b)\n",
    "    distance_matrix = [[0] * (len2 + 1) for k in range(len1 + 1)]\n",
    "\n",
    "    for i in range(len1 + 1):\n",
    "        distance_matrix[i][0] = i\n",
    "    for j in range(len2 + 1):\n",
    "        distance_matrix[0][j] = j\n",
    "\n",
    "    for i in range(1, len1 + 1):\n",
    "        for j in range(1, len2 + 1):\n",
    "            cost = 0 if a[i-1] == b[j-1] else 1\n",
    "            distance_matrix[i][j] = min(\n",
    "                distance_matrix[i-1][j] + 1,        \n",
    "                distance_matrix[i][j-1] + 1,        \n",
    "                distance_matrix[i-1][j-1] + cost    \n",
    "            )\n",
    "\n",
    "            if i > 1 and j > 1 and a[i-1] == b[j-2] and a[i-2] == b[j-1]:\n",
    "                distance_matrix[i][j] = min(distance_matrix[i][j], distance_matrix[i-2][j-2] + cost)\n",
    "\n",
    "    return distance_matrix[len1][len2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damerau_levenshtein_distance('sunday', 'sand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaro Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time complexitty: O(len1 × len2) in this case => O(6 × 4) = O(24) len(a) = 6 and len(b) = 4\n",
    "\n",
    "def jaro_similarity(a, b):\n",
    "    len1, len2 = len(a), len(b)\n",
    "    \n",
    "    if len1 == 0 and len2 == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    match_distance = (max(len1, len2) // 2) - 1\n",
    "    \n",
    "    matches1 = [0] * len1\n",
    "    matches2 = [0] * len2\n",
    "    \n",
    "    matches = 0\n",
    "    for i in range(len1):\n",
    "        start = max(0, i - match_distance)\n",
    "        end = min(len2, i + match_distance + 1)\n",
    "        for j in range(start, end):\n",
    "            if not matches2[j] and a[i] == b[j]:\n",
    "                matches1[i] = matches2[j] = True\n",
    "                matches += 1\n",
    "                break\n",
    "    \n",
    "    if matches == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    transpositions = 0\n",
    "    k = 0\n",
    "    for i in range(len1):\n",
    "        if matches1[i]:\n",
    "            while not matches2[k]:\n",
    "                k += 1\n",
    "            if a[i] != b[k]:\n",
    "                transpositions += 1\n",
    "            k += 1\n",
    "    \n",
    "    jaro_sim = (\n",
    "        (matches / len1) +\n",
    "        (matches / len2) +\n",
    "        ((matches - transpositions // 2) / matches)\n",
    "    ) / 3\n",
    "    \n",
    "    return jaro_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaro_similarity('sunday', 'sand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaro-Winkler Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time complexitty: O(len1 × len2) in this case => O(6 × 4) = O(24) len(a) = 6 and len(b) = 4\n",
    "\n",
    "def jaro_winkler_similarity(a, b, precomputed_jaro=None):\n",
    "\n",
    "    if precomputed_jaro is None:\n",
    "        precomputed_jaro = jaro_similarity(a, b)  \n",
    "\n",
    "    prefix_length = 0\n",
    "    max_prefix = 4\n",
    "    for i in range(min(len(a), len(b), max_prefix)):\n",
    "        if a[i] == b[i]:\n",
    "            prefix_length += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    jaro_winkler = precomputed_jaro + (prefix_length * 0.1 * (1 - precomputed_jaro))\n",
    "\n",
    "    return jaro_winkler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaro_winkler_similarity('sunday', 'sand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell Checker (computing distances manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Narmina\n",
      "[nltk_data]     Mehtiyeva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "nltk.download(\"words\") # caching technique (optiization)\n",
    "\n",
    "\n",
    "#function map (optimization)\n",
    "distance_functions = {\n",
    "    \"levenshtein\": levenshtein_distance_dp,\n",
    "    \"damerau_levenshtein\": damerau_levenshtein_distance,\n",
    "}\n",
    "similarity_functions = {\n",
    "    \"jaro_similarity\": jaro_similarity,\n",
    "    \"jaro_winkler\": jaro_winkler_similarity,\n",
    "}\n",
    "\n",
    "def compute_distance(word, correct_word, method):\n",
    "    if method in distance_functions:\n",
    "        return correct_word, distance_functions[method](word, correct_word)\n",
    "    similarity = similarity_functions[method](word, correct_word)\n",
    "    return correct_word, 1 - similarity\n",
    "\n",
    "def suggest_words(word, dictionary, method, max_suggestions=3, max_distance=2):\n",
    "    word_len = len(word)\n",
    "    precomputed_lengths = {w: len(w) for w in dictionary} #precompuation (optimization)\n",
    "    \n",
    "#parallel processing (optimization)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(compute_distance, word, correct_word, method)\n",
    "            for correct_word in dictionary\n",
    "            if abs(word_len - precomputed_lengths[correct_word]) <= max_distance #early filtering (optimization)\n",
    "        ]\n",
    "        suggestions = [\n",
    "            (correct_word, distance)\n",
    "            for future in futures\n",
    "            for correct_word, distance in [future.result()]\n",
    "            if distance <= max_distance\n",
    "        ]\n",
    "    return [w for w, k in sorted(suggestions, key=lambda x: x[1])[:max_suggestions]] # sorting (optimization)\n",
    "\n",
    "def main():\n",
    "    dictionary = set(words.words())\n",
    "    word = input(\"Enter a word to check: \").strip().lower()\n",
    "\n",
    "    if word in dictionary:\n",
    "        print(f\"'{word}' is correct!\")\n",
    "        return\n",
    "    for method in distance_functions | similarity_functions:\n",
    "        print(f\"\\nUsing {method.replace('_', ' ').title()}: {suggest_words(word, dictionary, method)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'set' is correct!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell Checker (using libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Narmina\n",
      "[nltk_data]     Mehtiyeva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import jellyfish\n",
    "from concurrent.futures import ThreadPoolExecutor  \n",
    "import time\n",
    "\n",
    "nltk.download(\"words\") # caching technique (optiization)\n",
    "\n",
    "# Precomputation (optimization)\n",
    "DICTIONARY = set(words.words())\n",
    "WORD_LENGTHS = {w: len(w) for w in DICTIONARY}\n",
    "\n",
    "def jaro_winkler_distance(w1, w2): #  Function Map (optimization)\n",
    "    return 1 - jellyfish.jaro_winkler_similarity(w1, w2)\n",
    "\n",
    "DISTANCE_FUNCTIONS = {\n",
    "    \"levenshtein\": jellyfish.levenshtein_distance,\n",
    "    \"damerau_levenshtein\": jellyfish.damerau_levenshtein_distance,\n",
    "    \"jaro_similarity\": lambda w1, w2: 1 - jellyfish.jaro_similarity(w1, w2),\n",
    "    \"jaro_winkler\": jaro_winkler_distance,\n",
    "}\n",
    "\n",
    "def compute_distance(word, correct_word, metric):\n",
    "    distance_func = DISTANCE_FUNCTIONS[metric]\n",
    "    distance = distance_func(word, correct_word)\n",
    "    return correct_word, distance\n",
    "\n",
    "def spell_check(word, dictionary, metric=\"levenshtein\", max_suggestions=3, max_distance=2):\n",
    "    start_time = time.time()\n",
    "\n",
    "    #Early Filtering + Precomputation (optimizations)\n",
    "    word_len = len(word)\n",
    "    first_letter = word[0]\n",
    "    candidate_words = [\n",
    "        w for w in dictionary\n",
    "        if abs(WORD_LENGTHS[w] - word_len) <= max_distance and w[0] == first_letter\n",
    "    ]\n",
    "    \n",
    "    suggestions = []\n",
    "    with ThreadPoolExecutor() as executor:  # Parallel Processing (optimization)\n",
    "        futures = [executor.submit(compute_distance, word, w, metric) for w in candidate_words]\n",
    "\n",
    "        for future in futures:\n",
    "            correct_word, distance = future.result()\n",
    "            if distance <= max_distance:\n",
    "                suggestions.append((correct_word, distance))\n",
    "\n",
    "    # Sorting (optimization)\n",
    "    suggestions.sort(key=lambda x: x[1])\n",
    "    result = [w for w, k in suggestions[:max_suggestions]]\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Spell check using {metric} completed in {end_time - start_time:.4f} seconds\")\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    word = input(\"Enter a word to check: \").strip().lower()\n",
    "\n",
    "    if word in DICTIONARY:\n",
    "        print(f\"'{word}' is correct!\")\n",
    "        return\n",
    "\n",
    "    print(f\"'{word}' not found. Suggestions:\")\n",
    "\n",
    "    for metric in [\"levenshtein\", \"damerau_levenshtein\", \"jaro_similarity\", \"jaro_winkler\"]:\n",
    "        suggestions = spell_check(word, DICTIONARY, metric=metric)\n",
    "        metric_name = metric.replace(\"_\", \" \").title()\n",
    "        print(f\"\\nUsing {metric_name}:\")\n",
    "        if suggestions:\n",
    "            print(f\"Input: {word} → Suggestions: {', '.join(suggestions)}\")\n",
    "        else:\n",
    "            print(\"No suggestions found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'miilk' not found. Suggestions:\n",
      "Spell check using levenshtein completed in 0.2960 seconds\n",
      "\n",
      "Using Levenshtein:\n",
      "Input: miilk → Suggestions: milk, mink, mail\n",
      "Spell check using damerau_levenshtein completed in 0.1480 seconds\n",
      "\n",
      "Using Damerau Levenshtein:\n",
      "Input: miilk → Suggestions: milk, mink, mail\n",
      "Spell check using jaro_similarity completed in 0.1920 seconds\n",
      "\n",
      "Using Jaro Similarity:\n",
      "Input: miilk → Suggestions: milk, milky, mil\n",
      "Spell check using jaro_winkler completed in 0.1770 seconds\n",
      "\n",
      "Using Jaro Winkler:\n",
      "Input: miilk → Suggestions: milk, milky, mil\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
